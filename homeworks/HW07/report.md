# HW07 – Report

> Файл: `homeworks/HW07/report.md`  
> Важно: не меняйте названия разделов (заголовков). Заполняйте текстом и/или вставляйте результаты.

## 1. Datasets

Вы выбрали 3 датасета из 4 (перечислите):
S07-hw-dataset-01.csv
S07-hw-dataset-02.csv
S07-hw-dataset-04.csv

### 1.1 Dataset A

- Файл: `S07-hw-dataset-01.csv`
- Размер: (12000 строк, 9 столбцов)
- Признаки: числовые (f01-f08), без пропусков
- Пропуски: нет
- "Подлости" датасета: признаки имеют разные масштабы (std от 7 до 60), возможны выбросы

### 1.2 Dataset B

- Файл: `S07-hw-dataset-02.csv`
- Размер: (8000 строк, 4 столбца)
- Признаки: числовые (x1, x2, z_noise), без пропусков
- Пропуски: нет
- "Подлости" датасета: признаки имеют разные стандартные отклонения (0.66-0.95), что может повлиять на расстояния в кластеризации


### 1.3 Dataset C

- Файл: `S07-hw-dataset-04.csv`
- Размер: (10000 строк, 33 столбцов)
- Признаки: 30 числовых (n01-n30) и 2 категориальных (cat_a, cat_b)
- Пропуски: да, примерно 2% пропущенных значений в числовых признаках (от 1.7% до 2.1%)
- "Подлости" датасета: высокая размерность, категориальные признаки требуют one-hot encoding, пропуски в данных


## 2. Protocol

Опишите ваш "честный" unsupervised-протокол.

- Препроцессинг: StandardScaler для числовых признаков, SimpleImputer со стратегией 'mean' для числовых и 'most_frequent' для категориальных, OneHotEncoder для категориальных признаков
- Поиск гиперпараметров:
    - KMeans: диапазон k от 2 до 20, фиксированный random_state=42, n_init=10
    - DBSCAN: eps = [0.5, 1, 1.5], min_samples = [3, 5, 10]
    - Руководствовались метрикой silhouette score для выбора "лучшего"
- Метрики: silhouette / Davies-Bouldin / Calinski-Harabasz (для DBSCAN с шумом метрики рассчитывались только на не-шумовых точках)
- Визуализация: PCA(2D) для понижения размерности и визуализации кластеров

## 3. Models

Перечислите, какие модели сравнивали **на каждом датасете**, и какие параметры подбирали.

Минимум (для каждого датасета):

- KMeans (поиск k в диапазоне [2, 20], фиксировали random_state=42, n_init=10)
- DBSCAN (eps в [0.5, 1, 1.5], min_samples в [3, 5, 10], отслеживалась доля шума)

## 4. Results

Для каждого датасета – краткая сводка результатов.

### 4.1 Dataset A

- Лучший метод и параметры: KMeans с k=2
- Метрики (silhouette / DB / CH): 0.522 / 0.685 / 11786.955
- DBSCAN: доля шума 0%, DBSCAN также нашел 2 кластера (eps=1.5, min_samples=3), но с худшим silhouette score (0.397)
- Коротко: KMeans с k=2 эффективно разделяет данные на два кластера, что подтверждается хорошими значениями метрик

### 4.2 Dataset B

- Лучший метод и параметры: KMeans с k=2
- Метрики (silhouette / DB / CH): 0.307 / 1.323 / 3573.393
- DBSCAN: не смог найти подходящие кластеры (все точки классифицированы как один кластер)
- Коротко: KMeans выделил 2 кластера, но с меньшим качеством по сравнению с датасетом А, DBSCAN не подошел для этих данных

### 4.3 Dataset C

- Лучший метод и параметры: KMeans с k=5
- Метрики (silhouette / DB / CH): 0.448 / 0.976 / 5103.100
- DBSCAN: не смог найти подходящие кластеры (все точки классифицированы как один кластер)
- Коротко: KMeans с k=5 показал хорошее качество, что может соответствовать пяти различным группам в данных, связанным с категориальными переменными

## 5. Analysis

### 5.1 Сравнение алгоритмов (важные наблюдения)

- KMeans работает хорошо при наличии четко выраженных кластеров, но чувствителен к масштабу признаков
- DBSCAN может быть неэффективен на данных с высокой размерностью или при отсутствии плотностных кластеров
- Масштабирование признаков значительно влияет на результаты, особенно для KMeans

### 5.2 Устойчивость (обязательно для одного датасета)

- Проверка устойчивости: 5 запусков KMeans с разными random_state (0, 10, 20, 30, 40)
- Результат: матрица ARI между всеми парами запусков содержит только 1.0, среднее ARI = 1.000
- Вывод: разбиения очень стабильны, что говорит о надежности выбранного алгоритма и параметров

### 5.3 Интерпретация кластеров

- Кластеры интерпретировались через анализ средних значений признаков в каждом кластере после обратного преобразования данных из препроцессора (до масштабирования)
- Для датасета 01: кластеры отличаются по значениям признаков f02, f04, f05, что может указывать на разные режимы или состояния в данных
- Для датасета 04: 5 кластеров с разными профилями числовых признаков, возможно соответствующих различным комбинациям категориальных переменных cat_a и cat_b
- PCA-визуализация показывает, что кластеры визуально разделимы в двумерном пространстве, что подтверждает качество кластеризации
- Вывод: кластеры содержат логически связанные наблюдения с похожими характеристиками, что делает результаты интерпретируемыми

## 6. Conclusion

- KMeans показывает стабильные и воспроизводимые результаты при правильных параметрах
- DBSCAN может быть менее предсказуемым, особенно на данных без четкой плотностной структуры
- Метрики silhouette, Davies-Bouldin и Calinski-Harabasz дополняют друг друга при оценке качества
- Препроцессинг данных (масштабирование, обработка пропусков) критически важен для успешной кластеризации
